# This github repository is updated with a new assignment 3, as per the request of collaborator
To run the code of notebook, just upload the videoplayback.mp4 and run all after setting GPU on. Done.




---- Past assignment 2A
# Explaining Model Predictions with Interpretability Techniques

In this notebook, we will explore various methods to explain the predictions of a Convolutional Neural Network (CNN) trained to classify images from the "Dogs vs. Cats" dataset. Understanding how a model makes predictions is crucial for improving its performance and ensuring transparency.

We will implement and visualize three key explainer techniques:
1. **Integrated Gradients**
2. **Grad-CAM (Gradient-weighted Class Activation Mapping)**

These methods help highlight the most important parts of the input image that contributed to the final decision made by the model.
